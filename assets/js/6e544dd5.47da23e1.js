"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[3126],{2845:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>d,contentTitle:()=>l,default:()=>u,frontMatter:()=>a,metadata:()=>c,toc:()=>h});var t=r(86070),s=r(25710),i=r(27676),o=r(65480);const a={},l="Distributed execution flow paradigms",c={permalink:"/blog/2024/08/27/distributed-execution-flow-paradigms",editUrl:"https://github.com/metatypedev/metatype/tree/main/docs/metatype.dev/blog/2024-08-27-distributed-execution-flow-paradigms/index.mdx",source:"@site/blog/2024-08-27-distributed-execution-flow-paradigms/index.mdx",title:"Distributed execution flow paradigms",description:"In this age of cloud development and microservices architecture, problems start to arise with the increased workloads that run in the system. Imagine an e-commerce platform where a customer places an order for a product during a high-demand sale event. The order triggers a series of interconnected processes: payment processing, inventory checks, packaging, shipping, and final delivery. Each of these processes might be handled by different microservices, potentially running on different servers or even in different data centers. What happens if the payment service goes down right after the payment is authorized but before the inventory is updated? Or if the packaging service fails just after the inventory is deducted but before the item is packed? Without a robust mechanism to ensure that each step in the workflow completes successfully and that failures are properly handled, you could end up with unhappy customers, lost orders, and inventory discrepancies.",date:"2024-08-27T00:00:00.000Z",tags:[],readingTime:10.93,hasTruncateMarker:!1,authors:[],frontMatter:{},unlisted:!1,nextItem:{title:"Programmatic deployment (v0.4.x)",permalink:"/blog/2024/05/09/programmatic-deployment"}},d={authorsImageUrls:[]},h=[{value:"1. Event-Driven Architecture with Message Queues",id:"1-event-driven-architecture-with-message-queues",level:3},{value:"Advantages",id:"advantages",level:4},{value:"Challenges",id:"challenges",level:4},{value:"2. The Saga Pattern",id:"2-the-saga-pattern",level:3},{value:"Advantages",id:"advantages-1",level:4},{value:"Drawbacks",id:"drawbacks",level:4},{value:"3. Stateful Orchestrators",id:"3-stateful-orchestrators",level:3},{value:"Advantages",id:"advantages-2",level:4},{value:"Challenges",id:"challenges-1",level:4},{value:"4. Durable Execution",id:"4-durable-execution",level:3},{value:"Advantages",id:"advantages-3",level:4},{value:"Challenges",id:"challenges-2",level:4}];function p(e){const n={a:"a",admonition:"admonition",code:"code",h3:"h3",h4:"h4",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components},{Details:a}=n;return a||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.p,{children:"In this age of cloud development and microservices architecture, problems start to arise with the increased workloads that run in the system. Imagine an e-commerce platform where a customer places an order for a product during a high-demand sale event. The order triggers a series of interconnected processes: payment processing, inventory checks, packaging, shipping, and final delivery. Each of these processes might be handled by different microservices, potentially running on different servers or even in different data centers. What happens if the payment service goes down right after the payment is authorized but before the inventory is updated? Or if the packaging service fails just after the inventory is deducted but before the item is packed? Without a robust mechanism to ensure that each step in the workflow completes successfully and that failures are properly handled, you could end up with unhappy customers, lost orders, and inventory discrepancies."}),"\n",(0,t.jsx)(n.p,{children:"Having multiple components in your system introduces more failure points, which is a common phenomenon in complex systems. But one important behavior any application must ensure is that the execution flow reaches its completion. As systems grow in features and complexity, the likelihood of long-running processes increases. To ensure these processes complete as intended, several solutions have been introduced over the last few decades.\nLet's explore some of the solutions that have been proposed to achieve workflow completeness."}),"\n",(0,t.jsx)(n.h3,{id:"1-event-driven-architecture-with-message-queues",children:"1. Event-Driven Architecture with Message Queues"}),"\n",(0,t.jsx)(n.p,{children:"This architecture relies heavily on services communicating by publishing and subscribing to events using message queues. Message queues are persistent storages that ensure data is not lost during failures or service unavailability. Components in a distributed system synchronize by using events/messages through these independent services. While this approach offers service decomposability and fault tolerance, it has some shortcomings. For example, using message queues comes with the overhead of managing messages (e.g., deduplication and message ordering). It also isn\u2019t ideal for systems requiring immediate consistency across components. Some technologies and patterns that utilize this architecture include:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://www.rabbitmq.com/",children:"RabbitMQ"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://aws.amazon.com/sqs/",children:"Amazon SQS"})}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{src:r(16676).A+""})}),"\n",(0,t.jsx)("div",{style:{marginLeft:"5em"},children:(0,t.jsx)(n.p,{children:"Fig. Event Driven Architecture with Message Queues - RabbitMQ"})}),"\n",(0,t.jsx)(n.h4,{id:"advantages",children:"Advantages"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Improved Scalability"}),"\n",(0,t.jsx)(n.li,{children:"Enhanced Responsiveness"}),"\n",(0,t.jsx)(n.li,{children:"Enhanced Fault Tolerance"}),"\n",(0,t.jsx)(n.li,{children:"Simplified Complex Workflows"}),"\n",(0,t.jsx)(n.li,{children:"Real-Time Data Processing"}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"challenges",children:"Challenges"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Event Ordering"}),"\n",(0,t.jsx)(n.li,{children:"Data Consistency"}),"\n",(0,t.jsx)(n.li,{children:"Monitoring and Debugging"}),"\n",(0,t.jsx)(n.li,{children:"Event Deduplication"}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"You can mitigate or reduce these challenges by following best practices like Event Sourcing, Idempotent Processing, CQRS (Command Query Responsibility Segregation), and Event Versioning."}),"\n",(0,t.jsxs)(n.h3,{id:"2-the-saga-pattern",children:["2. The ",(0,t.jsx)(n.a,{href:"https://microservices.io/patterns/data/saga.html",children:"Saga Pattern"})]}),"\n",(0,t.jsx)(n.p,{children:"This design pattern aims to achieve consistency across different services in a distributed system by breaking complex transactions spanning multiple components into a series of local transactions. Each of these transactions triggers an event or message that starts the next transaction in the sequence. If any local transaction fails to complete, a series of compensating actions roll back the effects of preceding transactions. While the orchestration of local transactions can vary, the pattern aims to achieve consistency in a microservices-based system. Events are designed to be stored in durable storage systems or logs, providing a trail to reconstruct the system to a state after a failure. While the saga pattern is an effective way to ensure consistency, it can be challenging to implement timer/timeout-based workflows and to design and implement the compensating actions for local transactions."}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Note"}),": In the Saga pattern, a compensating transaction must be idempotent and retryable. These principles ensure that transactions can be managed without manual intervention."]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{src:r(35936).A+""})}),"\n",(0,t.jsx)("div",{style:{marginLeft:"10em"},children:(0,t.jsx)(n.p,{children:"Fig. The Saga Pattern for Order delivery system"})}),"\n",(0,t.jsx)(n.h4,{id:"advantages-1",children:"Advantages"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Ensures data consistency in a distributed system without tight coupling."}),"\n",(0,t.jsx)(n.li,{children:"Provides Roll back if one of the operations in the sequence fails."}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"drawbacks",children:"Drawbacks"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Might be challenging to implement initially."}),"\n",(0,t.jsx)(n.li,{children:"Hard to debug."}),"\n",(0,t.jsx)(n.li,{children:"Compensating transactions don\u2019t always work."}),"\n"]}),"\n",(0,t.jsxs)(n.h3,{id:"3-stateful-orchestrators",children:["3. ",(0,t.jsx)(n.a,{href:"https://docs.oracle.com/en/applications/jd-edwards/cross-product/9.2/eotos/creating-a-stateful-orchestration-release-9-2-8-3.html#u30249073",children:"Stateful Orchestrators"})]}),"\n",(0,t.jsx)(n.p,{children:"Stateful orchestrators provide a solution for long-running workflows by maintaining the state of each step in a workflow. Each step in a workflow represents a task, and these tasks are represented as states inside workflows. Workflows are defined as state machines or directed acyclic graphs (DAGs). In this approach, an orchestrator handles task execution order, transitioning, handling retries, and maintaining state. In the event of a failure, the system can recover from the persisted state. Stateful orchestrators offer significant value in fault tolerance, consistency, and observability. It\u2019s one of the solutions proven effective in modern distributed computing. Some well-known services that provide this solution include:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/overview.html",children:"Apache Airflow"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://azure.microsoft.com/en-us/products/logic-apps",children:"Azure Logic Apps"})}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"advantages-2",children:"Advantages"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"High Resiliency"}),": Stateful orchestrators provide high resiliency in case of outages, ensuring that workflows can continue from where they left off."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Data Persistence"}),": They allow you to keep, review, or reference data from previous events, which is useful for long-running processes."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Extended Runtime"}),": Stateful workflows can continue running for much longer than stateless workflows, making them suitable for complex and long-running tasks."]}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"challenges-1",children:"Challenges"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Additional Complexity"}),": They introduce additional complexity, requiring you to manage issues such as load balancing, CPU and memory usage, and networking."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Cost"}),": With stateful workflows, you pay for the VMs that are running in the cluster, whereas with stateless workflows, you pay only for the actual compute resources consumed."]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"4-durable-execution",children:"4. Durable Execution"}),"\n",(0,t.jsx)(n.p,{children:"Durable execution refers to the ability of a system to preserve the state of an application and persist execution despite failures or interruptions. Durable execution ensures that for every task, its inputs, outputs, call stack, and local variables are persisted. These constraints, or rather features, allow a system to automatically retry or continue running in the face of infrastructure or system failures, ultimately ensuring completion."}),"\n",(0,t.jsx)(n.p,{children:"Durable execution isn\u2019t a completely distinct solution from the ones listed above but rather incorporates some of their strengths while presenting a more comprehensive approach to achieving consistency, fault tolerance, data integrity, resilience for long-running processes, and observability."}),"\n",(0,t.jsx)("img",{src:"/images/blog/execution-flow-paradigms/durable-exec.svg",alt:"Durable workflow engine - Temporal"}),"\n",(0,t.jsx)("div",{style:{marginLeft:"15em"},children:"Fig. Durable workflow engine"}),"\n",(0,t.jsx)(n.h4,{id:"advantages-3",children:"Advantages"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Reduced Manual Intervention"}),": Minimizes the need for human intervention by handling retries and failures programmatically."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Improved Observability"}),": Provides a clear audit trail and visibility into the state of workflows, which aids in debugging and monitoring."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Scalability"}),": Scales efficiently across distributed systems while maintaining workflow integrity."]}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"challenges-2",children:"Challenges"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Resource Intensive"}),": Persistent state storage and management can consume significant resources, especially in large-scale systems."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Latency"}),": The need to persist state and handle retries can introduce latency in the execution flow."]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"As durable execution grows to be a fundamental driver of distributed computing, some of the solutions which use this architecture are"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://temporal.io/",children:"Temporal"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://cadenceworkflow.io/",children:"Uber Cadence"})}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["Among these, ",(0,t.jsx)(n.a,{href:"https://temporal.io/",children:"Temporal"})," has grown in influence, used by companies like SnapChat, HashiCorp, Stripe, DoorDash, and DataDog. Its success is driven by its practical application in real-world scenarios and the expertise of its founders."]}),"\n",(0,t.jsxs)(n.p,{children:["At Metatype, we recognize the value of durable execution and are committed to making it accessible. Our ",(0,t.jsx)(n.a,{href:"/docs/reference/runtimes/temporal",children:"Temporal Runtime"})," integrates seamlessly into our declarative API development platform, enabling users to harness the power of Temporal directly within Metatype. For those interested in exploring further, our documentation provides a detailed guide on getting started with ",(0,t.jsx)(n.a,{href:"/docs/reference/runtimes/temporal",children:"Temporal Runtime"}),"."]}),"\n",(0,t.jsx)(n.p,{children:"Below is an example of how you can build a simple API to interact with an order delivery temporal workflow within Metatype."}),"\n",(0,t.jsx)(n.admonition,{type:"note",children:(0,t.jsxs)(n.p,{children:["If you are new to Metatype or haven\u2019t set it up yet in your development environment. You can follow this ",(0,t.jsx)(n.a,{href:"/docs/tutorials/quick-start",children:"guideline"}),"."]})}),"\n",(0,t.jsx)(n.p,{children:"For this example, the order delivery system will have few components/services such as Payment, Inventory and Delivery."}),"\n",(0,t.jsx)(n.p,{children:"Your temporal workflow definition should look similar to the one below."}),"\n",(0,t.jsxs)(o.Ay,{children:[(0,t.jsxs)(i.A,{value:"typescript",children:[(0,t.jsxs)(a,{children:[(0,t.jsxs)("summary",{children:["Activities definition inside ",(0,t.jsx)(n.code,{children:"src/activities.ts"}),":`"]}),(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:'async function sleep(time: number) {\n  return new Promise((resolve) => {\n    setTimeout(resolve, time);\n  });\n}\n\nexport async function processPayment(orderId: string): Promise<string> {\n  console.log(`Processing payment for order ${orderId}`);\n  // Simulate payment processing logic\n  await sleep(2);\n  return "Payment processed";\n}\n\nexport async function checkInventory(orderId: string): Promise<string> {\n  console.log(`Checking inventory for order ${orderId}`);\n  // Simulate inventory check logic\n  await sleep(2);\n  return "Inventory available";\n}\n\nexport async function deliverOrder(orderId: string): Promise<string> {\n  console.log(`Delivering order ${orderId}`);\n  // Simulate delivery logic\n  await sleep(5);\n  return "Order delivered";\n}\n'})})]}),(0,t.jsxs)(a,{children:[(0,t.jsxs)("summary",{children:["Workflow definition inside ",(0,t.jsx)(n.code,{children:"src/workflows.ts"}),":"]}),(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",metastring:'import {proxyActivities} from "@temporalio/workflow";',children:'\nexport const { processPayment, checkInventory, deliverOrder } =\n  proxyActivities<{\n    processPayment(orderId: string): Promise<string>;\n    checkInventory(orderId: string): Promise<string>;\n    deliverOrder(orderId: string): Promise<string>;\n  }>({\n    startToCloseTimeout: "10 seconds",\n  });\n\nexport async function OrderWorkflow(orderId: string): Promise<string> {\n  const paymentResult = await processPayment(orderId);\n  const inventoryResult = await checkInventory(orderId);\n  const deliveryResult = await deliverOrder(orderId);\n  return `Order ${orderId} completed with results: ${paymentResult}, ${inventoryResult}, ${deliveryResult}`;\n}\n'})})]}),(0,t.jsxs)(a,{children:[(0,t.jsxs)("summary",{children:["Worker definintion inside ",(0,t.jsx)(n.code,{children:"src/worker.ts"}),":"]}),(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:'import { NativeConnection, Worker } from "@temporalio/worker";\nimport * as activities from "./activities";\nimport { TASK_QUEUE_NAME } from "./shared";\n\nasync function run() {\n  const connection = await NativeConnection.connect({\n    address: "localhost:7233",\n  });\n\n  const worker = await Worker.create({\n    connection,\n    namespace: "default",\n    taskQueue: TASK_QUEUE_NAME,\n    workflowsPath: require.resolve("./workflows"),\n    activities,\n  });\n\n  await worker.run();\n}\n\nrun().catch((err) => {\n  console.error(err);\n  process.exit(1);\n});\n'})})]}),(0,t.jsxs)(n.p,{children:["After you have setup the above components, now you need a client to start of any ",(0,t.jsx)(n.code,{children:"OrderWorkflow"}),". Here is where metatype comes in, through the simple APIs ",(0,t.jsx)(n.a,{href:"/docs/reference/runtimes/temporal",children:"Temporal Runtime"})," exposes, you can communicate with your temporal cluster.\nDown below is the workflow communication bridge for this system expressed within a ",(0,t.jsx)(n.a,{href:"/docs/reference/typegraph",children:"typegraph"})," which includes endpoints to start a new workflow and describe an existing one."]}),(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:'import { Policy, t, typegraph } from "@typegraph/sdk/index.ts";\nimport { TemporalRuntime } from "@typegraph/sdk/providers/temporal.ts";\n\ntypegraph(\n  {\n    name: "order_delivery",\n  },\n  (g: any) => {\n    const pub = Policy.public();\n\n    const temporal = new TemporalRuntime({\n      name: "order_delivery",\n      hostSecret: "HOST",\n      namespaceSecret: "NAMESPACE",\n    });\n\n    const workflow_id = "order-delivery-1";\n\n    const order_id = t.string();\n\n    g.expose(\n      {\n        start: temporal.startWorkflow("OrderWorkflow", order_id),\n        describe: workflow_id\n          ? temporal.describeWorkflow().reduce({ workflow_id })\n          : temporal.describeWorkflow(),\n      },\n      pub,\n    );\n  },\n);\n'})})]}),(0,t.jsxs)(i.A,{value:"python",children:[(0,t.jsxs)(a,{children:[(0,t.jsxs)("summary",{children:["Activities definition inside ",(0,t.jsx)(n.code,{children:"activities.py"}),"."]}),(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'from temporalio import activity\nimport time\n\n@activity.defn\nasync def process_payment(order_id: str) -> str:\n    print(f"Processing payment for order {order_id}")\n    # Simulate payment processing logic\n    time.sleep(5)\n    return "Payment processed"\n\n@activity.defn\nasync def check_inventory(order_id: str) -> str:\n    print(f"Checking inventory for order {order_id}")\n    # Simulate inventory check logic\n    time.sleep(4)\n    return "Inventory available"\n\n@activity.defn\nasync def deliver_order(order_id: str) -> str:\n    print(f"Delivering order {order_id}")\n    time.sleep(8)\n    # Simulate delivery logic\n    return "Order delivered"\n'})})]}),(0,t.jsxs)(a,{children:[(0,t.jsxs)("summary",{children:["Worker defintion inside ",(0,t.jsx)(n.code,{children:"run_worker.py"}),"."]}),(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import asyncio\n\nfrom temporalio.client import Client\nfrom temporalio.worker import Worker\n\nfrom activities import process_payment, deliver_order, check_inventory\nfrom shared import ORDER_DELIVERY_QUEUE\nfrom workflows import OrderWorkflow\n\n\nasync def main() -> None:\n    client: Client = await Client.connect("localhost:7233", namespace="default")\n    worker: Worker = Worker(\n        client,\n        task_queue=ORDER_DELIVERY_QUEUE,\n        workflows=[OrderWorkflow],\n        activities=[process_payment, check_inventory, deliver_order],\n    )\n    await worker.run()\n\n\nif __name__ == "__main__":\n    asyncio.run(main())\n'})})]}),(0,t.jsxs)(n.p,{children:["After you have setup the above components, now you need a client to start of any ",(0,t.jsx)(n.code,{children:"OrderWorkflow"}),". Here is where metatype comes in, through the simple APIs ",(0,t.jsx)(n.a,{href:"/docs/reference/runtimes/temporal",children:"Temporal Runtime"})," exposes, you can communicate with your temporal cluster.\nDown below is the workflow communication bridge for this system expressed within a ",(0,t.jsx)(n.a,{href:"/docs/reference/typegraph",children:"typegraph"})," which includes endpoints to start a new workflow and describe an existing one."]}),(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'from typegraph import t, typegraph, Policy, Graph\nfrom typegraph.providers.temporal import TemporalRuntime\n\n\n@typegraph()\ndef example(g: Graph):\n  public = Policy.public()\n\n  temporal = TemporalRuntime(\n    "example", "HOST", namespace_secret="NAMESPACE"\n  )\n\n  workflow_id = "order-delivery-1"\n\n  order_id = t.string()\n\n  g.expose(\n    public,\n    start=temporal.start_workflow("OrderWorkflow", order_id),\n    describe=temporal.describe_workflow().reduce({"workflow_id": workflow_id})\n    if workflow_id\n    else temporal.describe_workflow(),\n  )\n'})})]})]}),"\n",(0,t.jsxs)(n.p,{children:["You need to add the secrets ",(0,t.jsx)(n.code,{children:"HOST"})," and ",(0,t.jsx)(n.code,{children:"NAMESPACE"})," under your typegraph name inside the ",(0,t.jsx)(n.code,{children:"metatype.yaml"})," file. These secrets are important to connect with your temporal cluster and can be safely stored in the config file as shown below."]}),"\n",(0,t.jsxs)(a,{children:[(0,t.jsx)("summary",{children:"metatype.yaml"}),(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-yaml",children:'typegates:\n  dev:\n    url: "http://localhost:7890"\n    username: admin\n    password: password\n    secrets:\n      example:\n        POSTGRES: "postgresql://postgres:password@postgres:5432/db"\n        MONGO: "mongodb://root:password@mongo:27017/db"\n        HOST: "http://localhost:7233"\n        NAMESPACE: "default"\n'})})]}),"\n",(0,t.jsxs)(n.p,{children:["You need to add only the last two lines as the others are auto-generated. Note that secrets are defined under the ",(0,t.jsx)(n.code,{children:"example"})," parent, which is the name of your typegraph. If the name doesn't match, you will face secret not found issues when deploying your typegraph."]}),"\n",(0,t.jsxs)(n.p,{children:["Before deploying the above typegraph, you need to start the temporal server and the worker. You need to have ",(0,t.jsx)(n.a,{href:"https://learn.temporal.io/getting_started/typescript/dev_environment/#set-up-a-local-temporal-service-for-development-with-temporal-cli",children:"temporal"})," installed on your machine."]}),"\n",(0,t.jsxs)(a,{children:[(0,t.jsx)("summary",{children:"Boot up temporal"}),(0,t.jsx)(n.p,{children:"Start the temporal server."}),(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"temporal server start-dev\n"})}),(0,t.jsx)(n.p,{children:"Start the worker."}),(0,t.jsxs)(o.Ay,{children:[(0,t.jsx)(i.A,{value:"typescript",children:(0,t.jsx)(n.p,{children:(0,t.jsx)(n.code,{children:"typescript npx ts-node src/worker.ts "})})}),(0,t.jsx)(i.A,{value:"python",children:(0,t.jsx)(n.code,{children:"python python run_worker.py "})})]})]}),"\n",(0,t.jsxs)(n.p,{children:["After booting the temporal server, run the command down below to get a locally spinning ",(0,t.jsx)(n.a,{href:"/docs/reference/typegate",children:"typegate"})," instance with your typegraph deployed."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"meta dev\n"})}),"\n",(0,t.jsxs)(n.p,{children:["After completing the above steps, you can access the web GraphQL client of the typegate at ",(0,t.jsx)(n.a,{href:"http://localhost:7890/example",children:(0,t.jsx)(n.code,{children:"http://localhost:7890/example"})}),". Run this query inside the client to start your workflow."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-graphql",children:'mutation {\n  start(\n    workflow_id: "order-delivery-3"\n    task_queue: "order-delivery-queue"\n    args: ["order12"]\n  )\n}\n'})}),"\n",(0,t.jsxs)(n.p,{children:["After a successful run, you will get the following result which includes the ",(0,t.jsx)(n.code,{children:"run_id"})," of the workflow which has just been started."]}),"\n",(0,t.jsx)("img",{src:"/images/blog/execution-flow-paradigms/start-workflow-result.png",alt:"Query result"}),"\n",(0,t.jsx)(n.p,{children:"You can also check the temporal web UI to monitor your workflows and you should see a result similar to this one."}),"\n",(0,t.jsx)("img",{src:"/images/blog/execution-flow-paradigms/temporal-web-ui.png",alt:"Workflows dashboard"}),"\n",(0,t.jsxs)(n.p,{children:["You can explore the ",(0,t.jsx)(n.a,{href:"/docs/reference/runtimes/temporal",children:"Temporal Runtime"})," for more info."]}),"\n",(0,t.jsx)(n.p,{children:"This wraps up the blog, thanks for reading until the end :)"})]})}function u(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(p,{...e})}):p(e)}},65480:(e,n,r)=>{r.d(n,{Ay:()=>o,gc:()=>a});r(30758);var t=r(3733),s=r(56315),i=r(86070);function o(e){let{children:n}=e;const[r,o]=(0,t.e)();return(0,i.jsx)(s.mS,{choices:{typescript:"Typescript SDK",python:"Python SDK"},choice:r,onChange:o,children:n})}function a(e){let{children:n}=e;const[r]=(0,t.e)();return(0,i.jsx)(s.q9,{choices:{typescript:"Typescript SDK",python:"Python SDK"},choice:r,children:n})}},16676:(e,n,r)=>{r.d(n,{A:()=>t});const t=r.p+"assets/images/eda.drawio-9d730aef7e9f00ffed737626d602be5c.svg"},35936:(e,n,r)=>{r.d(n,{A:()=>t});const t=r.p+"assets/images/saga.drawio-6f492c8332ead1021dde63fa7daf0efd.svg"}}]);