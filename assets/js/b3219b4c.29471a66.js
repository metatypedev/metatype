"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[3099],{83890:e=>{e.exports=JSON.parse('{"archive":{"blogPosts":[{"id":"/2024/08/27/distributed-execution-flow-paradigms","metadata":{"permalink":"/blog/2024/08/27/distributed-execution-flow-paradigms","editUrl":"https://github.com/metatypedev/metatype/tree/main/docs/metatype.dev/blog/2024-08-27-distributed-execution-flow-paradigms/index.mdx","source":"@site/blog/2024-08-27-distributed-execution-flow-paradigms/index.mdx","title":"Distributed execution flow paradigms","description":"In this age of cloud development and microservices architecture, problems start to arise with the increased workloads that run in the system. Imagine an e-commerce platform where a customer places an order for a product during a high-demand sale event. The order triggers a series of interconnected processes: payment processing, inventory checks, packaging, shipping, and final delivery. Each of these processes might be handled by different microservices, potentially running on different servers or even in different data centers. What happens if the payment service goes down right after the payment is authorized but before the inventory is updated? Or if the packaging service fails just after the inventory is deducted but before the item is packed? Without a robust mechanism to ensure that each step in the workflow completes successfully and that failures are properly handled, you could end up with unhappy customers, lost orders, and inventory discrepancies.","date":"2024-08-27T00:00:00.000Z","tags":[],"readingTime":10.92,"hasTruncateMarker":false,"authors":[],"frontMatter":{},"unlisted":false,"nextItem":{"title":"Python on WebAssembly: How?","permalink":"/blog/2024/08/26/python-on-webassembly"}},"content":"import TabItem from \\"@theme/TabItem\\";\\nimport SDKTabs from \\"@site/src/components/SDKTabs\\";\\n\\n\\nIn this age of cloud development and microservices architecture, problems start to arise with the increased workloads that run in the system. Imagine an e-commerce platform where a customer places an order for a product during a high-demand sale event. The order triggers a series of interconnected processes: payment processing, inventory checks, packaging, shipping, and final delivery. Each of these processes might be handled by different microservices, potentially running on different servers or even in different data centers. What happens if the payment service goes down right after the payment is authorized but before the inventory is updated? Or if the packaging service fails just after the inventory is deducted but before the item is packed? Without a robust mechanism to ensure that each step in the workflow completes successfully and that failures are properly handled, you could end up with unhappy customers, lost orders, and inventory discrepancies.\\n\\nHaving multiple components in your system introduces more failure points, which is a common phenomenon in complex systems. But one important behavior any application must ensure is that the execution flow reaches its completion. As systems grow in features and complexity, the likelihood of long-running processes increases. To ensure these processes complete as intended, several solutions have been introduced over the last few decades.\\nLet\'s explore some of the solutions that have been proposed to achieve workflow completeness.\\n\\n### 1. Event-Driven Architecture with Message Queues\\n\\nThis architecture relies heavily on services communicating by publishing and subscribing to events using message queues. Message queues are persistent storages that ensure data is not lost during failures or service unavailability. Components in a distributed system synchronize by using events/messages through these independent services. While this approach offers service decomposability and fault tolerance, it has some shortcomings. For example, using message queues comes with the overhead of managing messages (e.g., deduplication and message ordering). It also isn\u2019t ideal for systems requiring immediate consistency across components. Some technologies and patterns that utilize this architecture include:\\n\\n- [RabbitMQ](https://www.rabbitmq.com/)\\n- [Amazon SQS](https://aws.amazon.com/sqs/)\\n\\n![](eda.drawio.svg)\\n\\n<div style={{ marginLeft: 5 + \\"em\\" }}>\\n  Fig. Event Driven Architecture with Message Queues - RabbitMQ\\n</div>\\n\\n#### Advantages\\n\\n- Improved Scalability\\n- Enhanced Responsiveness\\n- Enhanced Fault Tolerance\\n- Simplified Complex Workflows\\n- Real-Time Data Processing\\n\\n#### Challenges\\n\\n- Event Ordering\\n- Data Consistency\\n- Monitoring and Debugging\\n- Event Deduplication\\n\\nYou can mitigate or reduce these challenges by following best practices like Event Sourcing, Idempotent Processing, CQRS (Command Query Responsibility Segregation), and Event Versioning.\\n\\n### 2. The [Saga Pattern](https://microservices.io/patterns/data/saga.html)\\n\\nThis design pattern aims to achieve consistency across different services in a distributed system by breaking complex transactions spanning multiple components into a series of local transactions. Each of these transactions triggers an event or message that starts the next transaction in the sequence. If any local transaction fails to complete, a series of compensating actions roll back the effects of preceding transactions. While the orchestration of local transactions can vary, the pattern aims to achieve consistency in a microservices-based system. Events are designed to be stored in durable storage systems or logs, providing a trail to reconstruct the system to a state after a failure. While the saga pattern is an effective way to ensure consistency, it can be challenging to implement timer/timeout-based workflows and to design and implement the compensating actions for local transactions.\\n\\n**Note**: In the Saga pattern, a compensating transaction must be idempotent and retryable. These principles ensure that transactions can be managed without manual intervention.\\n\\n![](saga.drawio.svg)\\n\\n<div style={{ marginLeft: 10 + \\"em\\" }}>\\n  Fig. The Saga Pattern for Order delivery system\\n</div>\\n\\n#### Advantages\\n\\n- Ensures data consistency in a distributed system without tight coupling.\\n- Provides Roll back if one of the operations in the sequence fails.\\n\\n#### Drawbacks\\n\\n- Might be challenging to implement initially.\\n- Hard to debug.\\n- Compensating transactions don\u2019t always work.\\n\\n### 3. [Stateful Orchestrators](https://docs.oracle.com/en/applications/jd-edwards/cross-product/9.2/eotos/creating-a-stateful-orchestration-release-9-2-8-3.html#u30249073)\\n\\nStateful orchestrators provide a solution for long-running workflows by maintaining the state of each step in a workflow. Each step in a workflow represents a task, and these tasks are represented as states inside workflows. Workflows are defined as state machines or directed acyclic graphs (DAGs). In this approach, an orchestrator handles task execution order, transitioning, handling retries, and maintaining state. In the event of a failure, the system can recover from the persisted state. Stateful orchestrators offer significant value in fault tolerance, consistency, and observability. It\u2019s one of the solutions proven effective in modern distributed computing. Some well-known services that provide this solution include:\\n\\n- [Apache Airflow](https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/overview.html)\\n- [Azure Logic Apps](https://azure.microsoft.com/en-us/products/logic-apps)\\n\\n#### Advantages\\n\\n- **High Resiliency**: Stateful orchestrators provide high resiliency in case of outages, ensuring that workflows can continue from where they left off.\\n- **Data Persistence**: They allow you to keep, review, or reference data from previous events, which is useful for long-running processes.\\n- **Extended Runtime**: Stateful workflows can continue running for much longer than stateless workflows, making them suitable for complex and long-running tasks.\\n\\n#### Challenges\\n\\n- **Additional Complexity**: They introduce additional complexity, requiring you to manage issues such as load balancing, CPU and memory usage, and networking.\\n- **Cost**: With stateful workflows, you pay for the VMs that are running in the cluster, whereas with stateless workflows, you pay only for the actual compute resources consumed.\\n\\n### 4. Durable Execution\\n\\nDurable execution refers to the ability of a system to preserve the state of an application and persist execution despite failures or interruptions. Durable execution ensures that for every task, its inputs, outputs, call stack, and local variables are persisted. These constraints, or rather features, allow a system to automatically retry or continue running in the face of infrastructure or system failures, ultimately ensuring completion.\\n\\nDurable execution isn\u2019t a completely distinct solution from the ones listed above but rather incorporates some of their strengths while presenting a more comprehensive approach to achieving consistency, fault tolerance, data integrity, resilience for long-running processes, and observability.\\n\\n<img\\n  src=\\"/images/blog/execution-flow-paradigms/durable-exec.svg\\"\\n  alt=\\"Durable workflow engine - Temporal\\"\\n/>\\n<div style={{ marginLeft: 15 + \\"em\\" }}>Fig. Durable workflow engine</div>\\n\\n#### Advantages\\n\\n- **Reduced Manual Intervention**: Minimizes the need for human intervention by handling retries and failures programmatically.\\n- **Improved Observability**: Provides a clear audit trail and visibility into the state of workflows, which aids in debugging and monitoring.\\n- **Scalability**: Scales efficiently across distributed systems while maintaining workflow integrity.\\n\\n#### Challenges\\n\\n- **Resource Intensive**: Persistent state storage and management can consume significant resources, especially in large-scale systems.\\n- **Latency**: The need to persist state and handle retries can introduce latency in the execution flow.\\n\\nAs durable execution grows to be a fundamental driver of distributed computing, some of the solutions which use this architecture are\\n\\n- [Temporal](https://temporal.io/)\\n- [Uber Cadence](https://cadenceworkflow.io/)\\n\\nAmong these, [Temporal](https://temporal.io/) has grown in influence, used by companies like SnapChat, HashiCorp, Stripe, DoorDash, and DataDog. Its success is driven by its practical application in real-world scenarios and the expertise of its founders.\\n\\nAt Metatype, we recognize the value of durable execution and are committed to making it accessible. Our [Temporal Runtime](/docs/reference/runtimes/temporal) integrates seamlessly into our declarative API development platform, enabling users to harness the power of Temporal directly within Metatype. For those interested in exploring further, our documentation provides a detailed guide on getting started with [Temporal Runtime](/docs/reference/runtimes/temporal).\\n\\nBelow is an example of how you can build a simple API to interact with an order delivery temporal workflow within Metatype.\\n\\n:::note\\nIf you are new to Metatype or haven\u2019t set it up yet in your development environment. You can follow this [guideline](/docs/tutorials/quick-start).\\n:::\\n\\nFor this example, the order delivery system will have few components/services such as Payment, Inventory and Delivery.\\n\\nYour temporal workflow definition should look similar to the one below.\\n\\n<SDKTabs>\\n\\n    <TabItem value=\\"typescript\\">\\n\\n<details>\\n\\n<summary>Activities definition inside `src/activities.ts`:`</summary>\\n\\n```typescript\\nasync function sleep(time: number) {\\n  return new Promise((resolve) => {\\n    setTimeout(resolve, time);\\n  });\\n}\\n\\nexport async function processPayment(orderId: string): Promise<string> {\\n  console.log(`Processing payment for order ${orderId}`);\\n  // Simulate payment processing logic\\n  await sleep(2);\\n  return \\"Payment processed\\";\\n}\\n\\nexport async function checkInventory(orderId: string): Promise<string> {\\n  console.log(`Checking inventory for order ${orderId}`);\\n  // Simulate inventory check logic\\n  await sleep(2);\\n  return \\"Inventory available\\";\\n}\\n\\nexport async function deliverOrder(orderId: string): Promise<string> {\\n  console.log(`Delivering order ${orderId}`);\\n  // Simulate delivery logic\\n  await sleep(5);\\n  return \\"Order delivered\\";\\n}\\n```\\n\\n</details>\\n\\n<details>\\n\\n<summary>Workflow definition inside `src/workflows.ts`:</summary>\\n```typescript import {proxyActivities} from \\"@temporalio/workflow\\";\\n\\nexport const { processPayment, checkInventory, deliverOrder } =\\n  proxyActivities<{\\n    processPayment(orderId: string): Promise<string>;\\n    checkInventory(orderId: string): Promise<string>;\\n    deliverOrder(orderId: string): Promise<string>;\\n  }>({\\n    startToCloseTimeout: \\"10 seconds\\",\\n  });\\n\\nexport async function OrderWorkflow(orderId: string): Promise<string> {\\n  const paymentResult = await processPayment(orderId);\\n  const inventoryResult = await checkInventory(orderId);\\n  const deliveryResult = await deliverOrder(orderId);\\n  return `Order ${orderId} completed with results: ${paymentResult}, ${inventoryResult}, ${deliveryResult}`;\\n}\\n```\\n</details>\\n\\n<details>\\n<summary>Worker definintion inside `src/worker.ts`:</summary>\\n\\n```typescript\\nimport { NativeConnection, Worker } from \\"@temporalio/worker\\";\\nimport * as activities from \\"./activities\\";\\nimport { TASK_QUEUE_NAME } from \\"./shared\\";\\n\\nasync function run() {\\n  const connection = await NativeConnection.connect({\\n    address: \\"localhost:7233\\",\\n  });\\n\\n  const worker = await Worker.create({\\n    connection,\\n    namespace: \\"default\\",\\n    taskQueue: TASK_QUEUE_NAME,\\n    workflowsPath: require.resolve(\\"./workflows\\"),\\n    activities,\\n  });\\n\\n  await worker.run();\\n}\\n\\nrun().catch((err) => {\\n  console.error(err);\\n  process.exit(1);\\n});\\n```\\n\\n</details>\\n\\nAfter you have setup the above components, now you need a client to start of any `OrderWorkflow`. Here is where metatype comes in, through the simple APIs [Temporal Runtime](/docs/reference/runtimes/temporal) exposes, you can communicate with your temporal cluster.\\nDown below is the workflow communication bridge for this system expressed within a [typegraph](/docs/reference/typegraph) which includes endpoints to start a new workflow and describe an existing one.\\n\\n```typescript\\nimport { Policy, t, typegraph } from \\"@typegraph/sdk/index.ts\\";\\nimport { TemporalRuntime } from \\"@typegraph/sdk/providers/temporal.ts\\";\\n\\ntypegraph(\\n  {\\n    name: \\"order_delivery\\",\\n  },\\n  (g: any) => {\\n    const pub = Policy.public();\\n\\n    const temporal = new TemporalRuntime({\\n      name: \\"order_delivery\\",\\n      hostSecret: \\"HOST\\",\\n      namespaceSecret: \\"NAMESPACE\\",\\n    });\\n\\n    const workflow_id = \\"order-delivery-1\\";\\n\\n    const order_id = t.string();\\n\\n    g.expose(\\n      {\\n        start: temporal.startWorkflow(\\"OrderWorkflow\\", order_id),\\n        describe: workflow_id\\n          ? temporal.describeWorkflow().reduce({ workflow_id })\\n          : temporal.describeWorkflow(),\\n      },\\n      pub,\\n    );\\n  },\\n);\\n```\\n\\n    </TabItem>\\n\\n    {/* break */}\\n    <TabItem value=\\"python\\">\\n\\n<details>\\n<summary>Activities definition inside `activities.py`.</summary>\\n\\n```python\\nfrom temporalio import activity\\nimport time\\n\\n@activity.defn\\nasync def process_payment(order_id: str) -> str:\\n    print(f\\"Processing payment for order {order_id}\\")\\n    # Simulate payment processing logic\\n    time.sleep(5)\\n    return \\"Payment processed\\"\\n\\n@activity.defn\\nasync def check_inventory(order_id: str) -> str:\\n    print(f\\"Checking inventory for order {order_id}\\")\\n    # Simulate inventory check logic\\n    time.sleep(4)\\n    return \\"Inventory available\\"\\n\\n@activity.defn\\nasync def deliver_order(order_id: str) -> str:\\n    print(f\\"Delivering order {order_id}\\")\\n    time.sleep(8)\\n    # Simulate delivery logic\\n    return \\"Order delivered\\"\\n```\\n\\n</details>\\n\\n<details>\\n<summary>Worker defintion inside `run_worker.py`.</summary>\\n\\n```python\\nimport asyncio\\n\\nfrom temporalio.client import Client\\nfrom temporalio.worker import Worker\\n\\nfrom activities import process_payment, deliver_order, check_inventory\\nfrom shared import ORDER_DELIVERY_QUEUE\\nfrom workflows import OrderWorkflow\\n\\n\\nasync def main() -> None:\\n    client: Client = await Client.connect(\\"localhost:7233\\", namespace=\\"default\\")\\n    worker: Worker = Worker(\\n        client,\\n        task_queue=ORDER_DELIVERY_QUEUE,\\n        workflows=[OrderWorkflow],\\n        activities=[process_payment, check_inventory, deliver_order],\\n    )\\n    await worker.run()\\n\\n\\nif __name__ == \\"__main__\\":\\n    asyncio.run(main())\\n```\\n\\n</details>\\n\\nAfter you have setup the above components, now you need a client to start of any `OrderWorkflow`. Here is where metatype comes in, through the simple APIs [Temporal Runtime](/docs/reference/runtimes/temporal) exposes, you can communicate with your temporal cluster.\\nDown below is the workflow communication bridge for this system expressed within a [typegraph](/docs/reference/typegraph) which includes endpoints to start a new workflow and describe an existing one.\\n\\n```python\\nfrom typegraph import t, typegraph, Policy, Graph\\nfrom typegraph.providers.temporal import TemporalRuntime\\n\\n\\n@typegraph()\\ndef example(g: Graph):\\n  public = Policy.public()\\n\\n  temporal = TemporalRuntime(\\n    \\"example\\", \\"HOST\\", namespace_secret=\\"NAMESPACE\\"\\n  )\\n\\n  workflow_id = \\"order-delivery-1\\"\\n\\n  order_id = t.string()\\n\\n  g.expose(\\n    public,\\n    start=temporal.start_workflow(\\"OrderWorkflow\\", order_id),\\n    describe=temporal.describe_workflow().reduce({\\"workflow_id\\": workflow_id})\\n    if workflow_id\\n    else temporal.describe_workflow(),\\n  )\\n```\\n\\n    </TabItem>\\n\\n</SDKTabs>\\n\\nYou need to add the secrets `HOST` and `NAMESPACE` under your typegraph name inside the `metatype.yaml` file. These secrets are important to connect with your temporal cluster and can be safely stored in the config file as shown below.\\n\\n<details>\\n<summary>metatype.yaml</summary>\\n\\n```yaml\\ntypegate:\\n  dev:\\n    url: \\"http://localhost:7890\\"\\n    username: admin\\n    password: password\\n    secrets:\\n      example:\\n        POSTGRES: \\"postgresql://postgres:password@postgres:5432/db\\"\\n        HOST: \\"http://localhost:7233\\"\\n        NAMESPACE: \\"default\\"\\n```\\n\\n</details>\\n\\nYou need to add only the last two lines as the others are auto-generated. Note that secrets are defined under the `example` parent, which is the name of your typegraph. If the name doesn\'t match, you will face secret not found issues when deploying your typegraph.\\n\\nBefore deploying the above typegraph, you need to start the temporal server and the worker. You need to have [temporal](https://learn.temporal.io/getting_started/typescript/dev_environment/#set-up-a-local-temporal-service-for-development-with-temporal-cli) installed on your machine.\\n\\n<details>\\n<summary>Boot up temporal</summary>\\n\\nStart the temporal server.\\n\\n```bash\\ntemporal server start-dev\\n```\\n\\nStart the worker.\\n\\n<SDKTabs>\\n\\n<TabItem value=\\"typescript\\">\\n  ```typescript npx ts-node src/worker.ts ```\\n</TabItem>\\n\\n<TabItem value=\\"python\\">```python python run_worker.py ```</TabItem>\\n\\n</SDKTabs>\\n</details>\\n\\nAfter booting the temporal server, run the command down below to get a locally spinning [typegate](/docs/reference/typegate) instance with your typegraph deployed.\\n\\n```bash\\nmeta dev\\n```\\n\\nAfter completing the above steps, you can access the web GraphQL client of the typegate at [`http://localhost:7890/example`](http://localhost:7890/example). Run this query inside the client to start your workflow.\\n\\n```graphql\\nmutation {\\n  start(\\n    workflow_id: \\"order-delivery-3\\"\\n    task_queue: \\"order-delivery-queue\\"\\n    args: [\\"order12\\"]\\n  )\\n}\\n```\\n\\nAfter a successful run, you will get the following result which includes the `run_id` of the workflow which has just been started.\\n\\n<img\\n  src=\\"/images/blog/execution-flow-paradigms/start-workflow-result.png\\"\\n  alt=\\"Query result\\"\\n/>\\n\\nYou can also check the temporal web UI to monitor your workflows and you should see a result similar to this one.\\n\\n<img\\n  src=\\"/images/blog/execution-flow-paradigms/temporal-web-ui.png\\"\\n  alt=\\"Workflows dashboard\\"\\n/>\\n\\nYou can explore the [Temporal Runtime](/docs/reference/runtimes/temporal) for more info.\\n\\nThis wraps up the blog, thanks for reading until the end :)"},{"id":"/2024/08/26/python-on-webassembly","metadata":{"permalink":"/blog/2024/08/26/python-on-webassembly","editUrl":"https://github.com/metatypedev/metatype/tree/main/docs/metatype.dev/blog/2024-08-26-python-on-webassembly/index.mdx","source":"@site/blog/2024-08-26-python-on-webassembly/index.mdx","title":"Python on WebAssembly: How?","description":"Metatype\'s different language runtimes are nice, but integrating one is an entire story. Let\'s discover how we managed to implement one for Python.","date":"2024-08-26T00:00:00.000Z","tags":[],"readingTime":11.125,"hasTruncateMarker":false,"authors":[],"frontMatter":{},"unlisted":false,"prevItem":{"title":"Distributed execution flow paradigms","permalink":"/blog/2024/08/27/distributed-execution-flow-paradigms"},"nextItem":{"title":"Programmatic deployment (v0.4.x)","permalink":"/blog/2024/05/09/programmatic-deployment"}},"content":"Metatype\'s different language runtimes are nice, but integrating one is an entire story. Let\'s discover how we managed to implement one for Python.\\n\\n## Why?\\n\\nYou have probably heard of \\"Function as a Service\\" or FaaS. \\nIn simple terms, FaaS are platforms that allow users to run code in response to events without the hassle of managing the underlying infrastructure. \\nUsers submit their programs and the platform takes care of the rest including, usually, scaling, availability, and configuration.\\nAWS Lambda is one such example and FaaS as a whole are a popular implementation of the serverless model.\\n\\nMetatype has this model at heart with applications composed of small functions that respond to events like http requests and authorization checks. \\nThis is achieved through runtimes like the [`DenoRuntime`](/docs/reference/runtimes/deno) which implements a way to execute functions authored in Typescript using Web Workers as implemented by [Deno](https://docs.deno.com/runtime/manual/runtime/workers/) (not based on Deno Deploy). \\n\\n:::note\\nMetatype supports running multiple apps or typegraphs on a single deployed cluster but we\'re still in the kitchen on a hosted cloud solution. \\nSubscribe to the [blog](https://metatype.dev/blog/rss.xml) or the [Github](https://github.com/metatypedev/metatype) repository for updates.\\n:::\\n\\nImplementing the `DenoRuntime` was a very straightforward affair as the Typegate (the engine at the heart of Metatype) is primarily written in Typescript and runs on a slightly modified version of the Deno runtime.\\nWhat\'s more, JavaScript has single threaded and asynchronous semantics and the v8 engine that it commonly runs on is of very high-quality by all regards. \\nThese qualities lend themselves very well to the requirements of running a serverless platform like security (good sandboxing) and performance (low start-up latencies).\\nThis fact is reflected in the dominance of JavaScript in the serverless market though it doesn\'t hurt that it\'s also the most popular language in use today.\\n\\nAnother very popular language is Python; and its standard library can be quite resourceful for this type of use case.\\nHowever, as we shall see, integrating the Python runtime isn\'t as simple as integrating Deno.\\n\\n## What are the requirements?\\n\\nThere are a number of Python runtimes available but a set of extra factors limit what we can achieve.\\n\\n1. **Security**: functions should have limited access to the execution environment. Python doesn\'t have built-in features for sandboxing out of the box unlike Deno.\\n2. **Speed**: functions should run fast and with low latency. We\'re interested in metrics like cold-start latency and overhead of any cross process/system communication.\\n3. **User-friendliness**: functionalities provided in any of the languages supported by Metatype should, within reason, mirror each other and maintain a degree of uniformity. We support inline code snippets and external file references for `DenoRuntime` and this should be the case for Python as well.\\n4. **Interoperability**: functions running in Python will need to have access to other parts of the app running on the Typegate like being able to invoke other functions.\\n\\nThe Typegate is a TypeScript program with a bit of Rust sprinkled in. \\nIt runs as a traditional POSIX process. \\nThink Linux containers. \\nThis fact renders multi-processing, one of the readily apparent approaches, undesirable as it would require investing is robust worker process management and distribution schemes.\\nIt\'d be great if we could keep everything inside the Typegate process.\\n\\nOne solution that presents itself here is the [PyO3](https://pyo3.rs/) project which provide Rust bindings to different Python runtimes like CPython and PyPy.\\nIt\'d not only allow us to run Python code in-process but it also provide an easy way to expose the functions written in Rust to Python and vice-versa. \\nA good solution for the bidirectional communication needed for our interoperability requirements.\\n\\nUnfortunately, PyO3 doesn\'t have any provisions for sandboxing which is critical for our use case.\\nThis is where WebAssembly enters into the picture. \\nWebAssembly or Wasm for short is a executable bytecode format that originates from the web world and is designed for applications that run inside web-browsers. \\nThis use case shares most of our requirements and the Wasm world promises excellent sandboxing properties that should be perfect for our use case.\\nWe just have to find a way to run Python inside of it.\\n\\n## An aside on WASI \\n\\nWebAssembly System Interface (WASI) is an additional spec for the bytecode format that formalizes how Wasm programs access their host environment.\\nA lot like POSIX, this generally means OS capabilities such as file system access and networking but also, in it\'s latest iteration extends to any custom host defined functionality.\\n\\nWasm + WASI fits very well to our use case. As opposed to mutli-processing, we can instantiate, manage, and expose resources programmatically with ease.\\nAnd as luck would have it, some [community work](https://github.com/vmware-labs/webassembly-language-runtimes) has already been done at the time that led to wasm builds of CPython being available.\\n\\nUnfortunately, the WASI spec itself is a work in progress.\\nWhen we started out, only the limited \\"[preview1](https://github.com/WebAssembly/WASI/blob/main/legacy/preview1/docs.md)\\" implementation was supported by most runtimes.\\n`preview1` only focused on a standard set of host functionalities much like a `libc` implementation.\\nWell enough but any custom functionality meant having to rely on simple C ABI alike functions for _intra_-process communication.\\nIn order to make this work easier, we elected to bring PyO3 back into the picture so that all the IPC stuff is written in Rust, the language with the most support in the Wasm ecosystem today.\\n\\nAll in all, this would mean the python interpreter wrapped in a PyO3 based native API.\\nAn assembly that accepts user code as strings and then invokes them in response to events.\\nAll of this would be running inside a Wasm runtime, [WasmEdge](https://wasmedge.org/) in this case, which ticks of all of the sandboxing and security requirements.\\nThis approach is well described as the [Reactor pattern](https://wasmcloud.com/blog/webassembly-patterns-command-reactor-library#the-reactor-pattern), a common pattern used in Wasm land.\\n\\n<img src=\\"/images/wasi_vfs_python_and_rust.svg\\" alt=\\"FIRST SOLUTION\\" />\\n\\n### File system access\\n\\nSince the PyO3 project doesn\'t support [statically linking](https://github.com/PyO3/pyo3/issues/416) the Python runtime, we\'ll need to find a way dynamically link `libpython`.\\nThankfully, Wasm does support [dynamic linking](https://github.com/WebAssembly/design/blob/main/DynamicLinking.md) and wasm builds of [`libpython`](https://github.com/vmware-labs/webassembly-language-runtimes/tree/main/python) are available curtsy of the WebAssembly Language Runtimes project. \\nBringing all of this together isn\'t as simple though as PyO3\'s tries to load `libpython` from certain _paths_, a concept that isn\'t exactly clearly defined in Wasm\'s post POSIX webtopia.\\n\\nOur first solution was to use [wasi-vfs](https://github.com/kateinoigakukun/wasi-vfs), a tool which allows you to embed a virtual file system, accessible through preview1 APIs, directly into your wasm binaries.\\nThis way, we could prepare a single wasm artifact that contains both the `libpython` build and the custom glue code.\\n\\nThis approach turned out to be quite hacky though and after encountering several issues, we ultimately decided to go with **preopens**.\\nPreopens are another virtual file-system solution where you map an actual file-system directory to a virtual directory visible to a running Wasm instance.\\nThis means we\'ll need to prepare the `libpython` Wasm file on disk before running the instance but it was an acceptable solution.\\nWe also use preopens to provide some of the user submitted code to our custom python runtime.\\n\\nThe following rust snippet demonstrates the preopens looked like in use:\\n\\n```rust\\nfn init_Python_vm() -> Result<Rt> {\\n  let preopens = vec![\\n    // User script will be uploaded at ./src/Python which is virtually seen as /app\\n    // Each script has access only to /app\\n    \\"/app:./src/Python:readonly\\".to_owned()\\n  ];\\n\\n  // This follow the same idea as above, but for clarity\'s sake we decided to separate it\\n  let pylib = PathBuf::from(\\"./vendor/libpython/usr/local/lib\\");\\n\\n  // This is our wasm module reponsible for running Python scripts at runtime\\n  // It assumes /app and libpython to be available in its world\\n  let wasi_mod = PathBuf::from(\\"./build/Python-wasi-reactor.wasm\\");\\n\\n  // Now we can instantiate the WASI module with all the configurations above\\n  let rt = instantiate_custom_python_runtime(preopens, pylib, wasi_mod)?;\\n  rt.run_func(None, \\"init_Python\\", params!())?;\\n\\n  // ..\\n\\n  Ok(rt)\\n}\\n```\\n\\n### WASI 0.2\\n\\nThe solution described above worked well to an extent but the limitations of preview1 and all the wrangling with PyO3 resulted in complexity that we were always ready to get rid of.\\nThis was exactly what we did after the Bytecode Alliance finalized [WASI 0.2](https://bytecodealliance.org/articles/WASI-0.2) back in January 2024 and with it, a slew of new opportunuties.\\n\\nWASI 0.2 introduces a whole new concept of components, wasm modules that come with pre-specifed interfaces using the [Wit](https://github.com/WebAssembly/component-model/blob/main/design/mvp/WIT.md) format and based on a whole new [ABI](https://github.com/WebAssembly/component-model/blob/main/design/mvp/CanonicalABI.md) to boot.\\nThese new capabilities suggest that it should possible to replace our PyO3 based glue code with the WASI based layer. \\nLet\'s see how.\\n\\nWe first used the new found WASI powers to implement support for Wasm based functions through the [`WasmRuntime`](/docs/reference/runtimes/wasm).\\nThis lead us to implement the [`wit_wire`](https://github.com/metatypedev/metatype/blob/2e692b9ae9e48b6e1a863130fc1bfbdd004cb631/src/wit/wit-wire.wit) protocol, a simple JSON based WIT interface that\'d be used by any wasm component that intenteds to run on the `WasmRuntime`.\\nSimple enough that it\'s reproduced down below in it\'s entirety.\\n\\n```wit\\npackage metatype:wit-wire;\\n\\n// what the host provides\\ninterface typegate-wire {\\n  hostcall: func(op-name: string, json: string) -> result<string, string>;\\n}\\n\\n// what\'s expected from the guest\\ninterface mat-wire {\\n\\n  // init function called when we first make the component\\n  init: func(args: init-args) -> result<init-response, init-error>;\\n  // general purpose event handler\\n  handle: func(req: handle-req) -> result<json-str, handle-err>;\\n\\n  type json-str = string;\\n\\n  record init-args {\\n    // the list of operations the application is expecting\\n    // from this component\\n    expected-ops: list<mat-info>\\n    metatype-version: string,\\n  }\\n\\n  record mat-info {\\n    op-name: string,\\n    mat-title: string,\\n    mat-data-json: string,\\n  }\\n\\n  record init-response {\\n    ok: bool\\n  }\\n\\n  variant init-error {\\n    version-mismatch(string),\\n    unexpected-mat(mat-info),\\n    other(string)\\n  }\\n\\n  record handle-req {\\n    op-name: string,\\n    in-json: json-str,\\n  }\\n\\n  variant handle-err {\\n    no-handler,\\n    in-json-err(string),\\n    handler-err(string),\\n  }\\n}\\n\\n// a world defines what interfaces get imported\\n// and exported\\nworld wit-wire {\\n  import typegate-wire;\\n\\n  export mat-wire;\\n}\\n\\n```\\n\\nSquint your eyes tight enough and the `wit_wire` protocol as implemented wasn\'t far off from what the PyO3 based glue code was doing in the previous implementation.\\nSpecifically, register a list of operations that the Typegate is expecting from the module and execute them for incoming event.\\nWe just need to add support for the operation metadata to contain extra items.\\nIn the case of the [`PythonRuntime`](/docs/reference/runtimes/python), this would be the Python code itself.\\n\\nNow that we have the `wit_wire` implementation taking care of bidirectional communication, we have little reason to keep the PyO3 based glue code around.\\nThis glue was doing a bit more than acting as a boundary though.\\nIt was also responsible for setting up the operating environment for the Python code.\\nFor example, we\'d need some kind of initialization to execute the user\'s Python snippets which are in free standing `lambda` form. \\nHow does one create components out of Python anyways?\\n\\n[componentize-py](https://github.com/bytecodealliance/componentize-py) is a tool authored by the Bytecode Alliance that allows you to produce WASI components that are authored in Python.\\nIt has code generation suite that emits guest bindings in Python for any WIT specification you feed it.\\nIt then takes your Python code written against these bindings and embeds them in a Wasm build of the Python interpreter to produce a component that supports the specified Wit.\\n\\nUnsurprisingly, componentize-py relies on PyO3 and preopens itself in addition to [component-init](https://github.com/dicej/component-init), a solution to pre-intialize components up to a certain point for improved startup latencies.\\nThis pre-intialization means we won\'t need to provide the actual preopens for the resulting component, baking the `libpython` object code directly into it as PyO3 will have dynamically loaded the object code by that point.\\nUltimately, this allows us to write all of our glue code in Python itself.\\n\\nWe still need a bit of Rust to support the `wit_wire` interface on the Typegate but this implementation is general across both the `PythonRuntime` and `WasmRuntime`.\\nWe\'d also moved to the [Wasmtime](https://wasmtime.dev/), also by Bytecode Alliance, for our wasm workloads at this point and their Rust bindings are a pleasure to use.\\nIt\'s all smooth sailing from here.\\n\\n## Cloudy skies?\\n\\nA final stumbling block for this approach was the many seconds Wasmtime spends cooking all your CPU cores when it compiles the fat wasm module that contains the Python interpreter, Pyo3 bindings and more.\\nThis happens because Wasmtime does\'t ([yet](https://github.com/bytecodealliance/rfcs/blob/main/accepted/wasmtime-baseline-compilation.md)) implement any schemes for tiered compilation, all code being greeted by their optimizing compiler, Cranelift.\\nAnd optimizations take time.\\nSure, you only pay this cost the first time you load the Python runtime module as Wasmtime has great support for caching including on-disk caching.\\nBut, 10+ second cold-starts, as measured on one developer\'s machine, are unacceptable in a system that primarily serves HTTP requests.\\nWhat to do?\\n\\nWasmtime has just the feature for this problem, [pre-compilation](https://docs.wasmtime.dev/cli-options.html#compile).\\nAhead-of-time compilation of wasm bytecode into a native instruction set.\\nSuch files are commonly given the `.cwasm` extesion, _c_ for compiled, and they are not a standalone executable but inteded to be run within Wasmtime\'s sandbox.\\nThis eliminates the compliation cost but the semantics of the source wasm bytecode and the runtime safe-guards means that this should be just as safe as JITting it (just-in-time compilation).\\nWe then statically embed this pre-compiled wasm artifact, after compressing it, in the Typegate binary removing the need for sidecar files while ensuring minimal cold-starts for our python workloads.\\nTo be concrete, this means _roughly_ around 200 ms of overhead for a cold function and 5 ms for a warm one.\\nGood enough.\\n\\nThis post describes the technical journey we took to arrive to the current implementation of the `PythonRuntime`. Hopefully, all details were clear enough and please direct any feedback, questions, and thoughts to the comments down below and our Github issues/discussion board."},{"id":"/2024/05/09/programmatic-deployment","metadata":{"permalink":"/blog/2024/05/09/programmatic-deployment","editUrl":"https://github.com/metatypedev/metatype/tree/main/docs/metatype.dev/blog/2024-05-09-programmatic-deployment/index.mdx","source":"@site/blog/2024-05-09-programmatic-deployment/index.mdx","title":"Programmatic deployment (v0.4.x)","description":"A new approach to deploying typegraphs has been introduced starting with version 0.4.0. This aims to facilitate the development of automation tools around the APIs you build within the Metatype ecosystem.","date":"2024-05-09T00:00:00.000Z","tags":[],"readingTime":3.405,"hasTruncateMarker":false,"authors":[],"frontMatter":{},"unlisted":false,"prevItem":{"title":"Python on WebAssembly: How?","permalink":"/blog/2024/08/26/python-on-webassembly"},"nextItem":{"title":"The Node/Deno SDK is now available","permalink":"/blog/2023/11/27/node-compatibility"}},"content":"import SDKTabs from \\"@site/src/components/SDKTabs\\";\\nimport TabItem from \\"@theme/TabItem\\";\\nimport UpgradePythonSDK from \\"../../shared/upgrade/python-sdk.mdx\\";\\nimport UpgradeTsSDK from \\"../../shared/upgrade/typescript-sdk.mdx\\";\\n\\n\\nA new approach to deploying typegraphs has been introduced starting with version 0.4.0. This aims to facilitate the development of automation tools around the APIs you build within the Metatype ecosystem.\\n\\n## What has changed?\\n\\nBefore v0.4.x, we had to entirely rely on the [meta cli](/docs/reference/meta-cli) to deploy typegraphs to a typegate instance.\\n\\nThis is no longer the case, as all core logic has been moved to the TypeScript/Python typegraph SDKs, both of which share the same WebAssembly-based **typegraph-core** behind the scenes. This provides some degree of assurance that you will have nearly identical experiences with each SDK.\\n\\n## What are the use-cases?\\n\\nSince typegraphs can be written using the programming language your preferred SDK is based on, you can dynamically create typegraphs with ease.\\n\\nThe missing piece was having an interface natively backed inside the SDK for doing deployment programmatically.\\n\\n### Programmatic deployment\\n\\n### Initial setup\\n\\nJust like any other dependency in your favorite programming language, each SDKs can be installed with your favorite package manager.\\n\\nYou can use one of the commands below to get started with the latest available version.\\n\\n<SDKTabs>\\n  <TabItem value=\\"typescript\\">\\n    <UpgradeTsSDK />\\n  </TabItem>\\n  <TabItem value=\\"python\\">\\n    <UpgradePythonSDK />\\n  </TabItem>\\n</SDKTabs>\\n\\n#### Configuration\\n\\nThis is analoguous to the yaml configuration file when you are using [meta cli](/docs/reference/meta-cli).\\n\\nIt\'s the place where you tell which typegate you want to deploy to, how you want the artifacts to be resolved, among other settings.\\n\\n<SDKTabs>\\n    <TabItem value=\\"python\\">\\n\\n```python\\nconfig: TypegraphDeployParams = TypegraphDeployParams(\\n        typegate=TypegateConnectionOptions(url=\\"<TYPEGATE_URL>\\", auth=BasicAuth(\\"<USERNAME>\\", \\"<PASSWORD>\\")),\\n        typegraph_path=os.path.join(cwd, \\"path-to-typegraph\\"),\\n        prefix=\\"\\",\\n        secrets={},\\n        migrations_dir=path.join(\\"prisma-migrations\\", example.name),\\n        migration_actions=None,\\n        default_migration_action=MigrationAction(\\n            apply=True,\\n            reset=True,  # allow destructive migrations\\n            create=True,\\n        ),\\n    )\\n```\\n\\n    </TabItem>\\n    <TabItem value=\\"typescript\\">\\n\\n```typescript\\nconst config = {\\n  typegate: {\\n    url: \\"<TYPEGATE_URL>\\",\\n    auth: new BasicAuth(\\"<USERNAME>\\", \\"<PASSWORD>\\"),\\n  },\\n  typegraphPath: path.join(cwd, \\"path-to-typegraph.ts\\"),\\n  prefix: \\"\\",\\n  secrets: { POSTGRES: \\"<DB_URL>\\" },\\n  migrationsDir: path.join(\\"prisma-migrations\\", tg.name),\\n  defaultMigrationAction: {\\n    create: true,\\n    reset: true, // allow destructive migrations\\n  },\\n};\\n```\\n\\n    </TabItem>\\n\\n</SDKTabs>\\n\\n### Deploy/remove\\n\\nNow, picture this, you have a lot of typegraphs and one or more typegate instance(s) running, you can easily make small scripts that does any specific job you want.\\n\\n```typescript\\n// ..\\nimport { tgDeploy, tgRemove } from \\"@typegraph/sdk/tg_deploy.js\\";\\n// ..\\n\\nconst BASIC_AUTH = loadMyAuthsFromSomeSource();\\nconst TYPEGATE_URL = \\"...\\";\\n\\nexport async function getTypegraphs() {\\n  // Suppose we have these typegraphs..\\n  // Let\'s enumerate them like this to simplify\\n  return [\\n    {\\n      tg: await import(\\"path/to/shop-finances\\"),\\n      location: \\"path/to/shop-finances.ts\\",\\n    },\\n    {\\n      tg: await import(\\"path/to/shop-stats\\"),\\n      location: \\"path/to/shop-stats.ts\\",\\n    },\\n  ];\\n}\\n\\nexport function getConfig(tgName: string, tgLocation: string) {\\n  // Note: You can always develop various ways of constructing the configuration,\\n  // like loading it from a file.\\n  return {\\n    typegate: {\\n      url: \\"<TYPEGATE_URL>\\",\\n      auth: new BasicAuth(\\"<USERNAME>\\", \\"<PASSWORD>\\"),\\n    },\\n    typegraphPath: path.join(cwd, \\"path-to-typegraph.ts\\"),\\n    prefix: \\"\\",\\n    secrets: { POSTGRES: \\"<DB_URL>\\" },\\n    migrationsDir: path.join(\\"prisma-migrations\\", tg.name),\\n    defaultMigrationAction: {\\n      create: true,\\n      reset: true, // allow destructive migrations\\n    },\\n  };\\n}\\n\\nexport async function deployAll() {\\n  const typegraphs = await getTypegraphs();\\n  for (const { tg, location } of typegraphs) {\\n    try {\\n      const config = getConfig(tg.name, location);\\n      // use tgDeploy to deploy typegraphs, it will contain the response from typegate\\n      const { typegate } = await tgDeploy(tg, config);\\n      const selection = typegate?.data?.addTypegraph;\\n      if (selection) {\\n        const { messages } = selection;\\n        console.log(messages.map(({ text }) => text).join(\\"\\\\n\\"));\\n      } else {\\n        throw new Error(JSON.stringify(typegate));\\n      }\\n    } catch (e) {\\n      console.error(\\"[!] Failed deploying\\", tg.name);\\n      console.error(e);\\n    }\\n  }\\n}\\n\\nexport async function undeployAll() {\\n  const typegraphs = await getTypegraphs();\\n  for (const { tg } of typegraphs) {\\n    try {\\n      // use tgRemove to remove typegraphs\\n      const { typegate } = await tgRemove(\\"<TYPEGRAPH_NAME>\\", {\\n        baseUrl: TYPEGATE_URL,\\n        auth: BASIC_AUTH,\\n      });\\n      console.log(typegate);\\n    } catch (e) {\\n      console.error(\\"Failed removing\\", tg.name);\\n      console.error(e);\\n    }\\n  }\\n}\\n```\\n\\n### Going beyond\\n\\nWith these new additions, you can automate virtually anything programmatically on the typegraph side. Starting from having highly dynamic APIs to providing ways to deploy and configure them, you can even build a custom framework around the ecosystem!\\n\\nPlease tell us what you think and report any issues you found on [Github](https://github.com/metatypedev/metatype/issues).\\n\\n:::info Notes\\n\\nYou can check the [Programmatic deployment](/docs/guides/programmatic-deployment) reference page for more information.\\n\\n:::"},{"id":"/2023/11/27/node-compatibility","metadata":{"permalink":"/blog/2023/11/27/node-compatibility","editUrl":"https://github.com/metatypedev/metatype/tree/main/docs/metatype.dev/blog/2023-11-27-node-compatibility/index.mdx","source":"@site/blog/2023-11-27-node-compatibility/index.mdx","title":"The Node/Deno SDK is now available","description":"We are happy to announce that we have redesigned our SDKs to support Node/Deno and facilitate the integration of future languages. Most of the typegraph SDK is now written in Rust and shaped around a core interface running in WebAssembly.","date":"2023-11-27T00:00:00.000Z","tags":[],"readingTime":1.7,"hasTruncateMarker":false,"authors":[],"frontMatter":{},"unlisted":false,"prevItem":{"title":"Programmatic deployment (v0.4.x)","permalink":"/blog/2024/05/09/programmatic-deployment"},"nextItem":{"title":"Programmable glue for developers","permalink":"/blog/2023/06/18/programmable-glue"}},"content":"We are happy to announce that we have redesigned our SDKs to support Node/Deno and facilitate the integration of future languages. Most of the [typegraph SDK](/docs/reference/typegraph) is now written in Rust and shaped around a core interface running in WebAssembly.\\n\\n## Meet `wit`\\n\\nIn the realm of WebAssembly, the [wit-bindgen](https://github.com/bytecodealliance/wit-bindgen) project emerges as the most mature tool to create and maintain the language bindings for WebAssembly modules. This tool introduces WIT (WebAssembly Interface Types) as an Interface Definition Language (IDL) to describe the imports, exports, and capabilities of WebAssembly components seamlessly.\\n\\nFor example, Metatype implements the reactor pattern to handle requests as they come and delegate part of their execution in correct WASM runtime. The wit-bindgen helps there to define the interfaces between the guest (the Metatype runtime) and the host (the typegate) to ensure the correct serialization of the payloads. The `wit` definition could look like this:\\n\\n```\\npackage metatype:wit-wire;\\n\\ninterface typegate-wire {\\n  hostcall: func(op-name: string, json: string) -> result<string, string>;\\n}\\n\\ninterface mat-wire {\\n  record handle-req {\\n    op-name: string,\\n    in-json: string,\\n  }\\n\\n  handle: func(req: handle-req) -> result<string, string>;\\n}\\n\\nworld wit-wire {\\n  import typegate-wire;\\n\\n  export mat-wire;\\n}\\n```\\n\\nThe `wit` file is then used to generate the bindings for the host and the guest in Rust, TypeScript, Python, and other languages. The host bindings are used in the typegate to call the WASM runtime, and the guest bindings are used in the WASM runtime to call the typegate.\\n\\n## Install the v0.2.x series\\n\\nThe documentation contains now examples for Node and Deno.\\n\\n### Upgrade with Node\\n\\n```bash\\nnpm install @typegraph/sdk\\nmeta new --template node .\\n```\\n\\n### Upgrade with Deno\\n\\n```bash\\nmeta new --template deno .\\n```\\n\\n```typescript\\nimport { typegraph } from \\"npm:@typegraph/sdk/index.js\\";\\n```\\n\\n### Upgrade with Python\\n\\n```python\\npip3 install --upgrade typegraph\\npoetry add typegraph@latest\\n```\\n\\n## Give us feedback!\\n\\nThis new release enables us to provide a consistent experience across all languages and reduce the work to maintain the existing Python SDK.\\n\\nAs always, report issues and let us know what you think on [GitHub](https://github.com/metatypedev/metatype/discussions)."},{"id":"/2023/06/18/programmable-glue","metadata":{"permalink":"/blog/2023/06/18/programmable-glue","editUrl":"https://github.com/metatypedev/metatype/tree/main/docs/metatype.dev/blog/2023-06-18-programmable-glue/index.mdx","source":"@site/blog/2023-06-18-programmable-glue/index.mdx","title":"Programmable glue for developers","description":"We are introducing Metatype, a new project that allows developers to build modular and strongly typed APIs using typegraph as a programmable glue.","date":"2023-06-18T00:00:00.000Z","tags":[],"readingTime":1.295,"hasTruncateMarker":false,"authors":[],"frontMatter":{},"unlisted":false,"prevItem":{"title":"The Node/Deno SDK is now available","permalink":"/blog/2023/11/27/node-compatibility"},"nextItem":{"title":"Emulating your server nodes locally","permalink":"/blog/2023/03/15/emulating-servers"}},"content":"import { CompareLandscape } from \\"@site/src/components/CompareLandscape\\";\\nimport Metatype from \\"@site/shared/metatype-intro.mdx\\";\\nimport TGExample from \\"@site/src/components/TGExample\\";\\n\\n\\nWe are introducing Metatype, a new project that allows developers to build modular and strongly typed APIs using typegraph as a programmable glue.\\n\\n## What is Metatype?\\n\\n<Metatype />\\n\\n## What are virtual graphs?\\n\\nTypegraphs are a declarative way to expose all APIs, storage and business logic of your stack as a single graph. They take inspiration from domain-driven design principles and in the idea that the relation between of the data is as important as data itself, even though they might be in different locations or shapes.\\n\\n<TGExample\\n  python={require(\\"!!code-loader!../../../../examples/typegraphs/index.py\\")}\\n  typescript={require(\\"!!code-loader!../../../../examples/typegraphs/index.ts\\")}\\n  typegraph=\\"homepage\\"\\n  variables={{ email: \\"fill-me\\", message: \\"Great tool!\\" }}\\n  defaultMode=\\"typegraph\\"\\n  query={require(\\"../../src/pages/index.graphql\\")}\\n/>\\n\\nThese elements can then be combined and composed together similarly on how you would compose web components to create an interface in modern frontend practices. This allows developers to build modular and strongly typed APIs using typegraph as a programmable glue.\\n\\n## Where does this belong in the tech landscape?\\n\\nBefore Metatype, there was a gap in the technological landscape for a solution that specifically addressed the transactional, short-lived use cases. While there were existing tools for analytical or long-running use cases, such as Trino and Temporal, there was no generic engine for handling transactional, short-lived tasks.\\n\\n    <CompareLandscape />\\n\\n## Give it a try!\\n\\nLet us know what you think! Metatype is open source and we welcome any feedback or contributions. The community primarily lives on [GitHub](https://github.com/metatypedev/metatype).\\n\\n:::info Next steps\\n\\n[Build your first typegraph](/docs/tutorials/metatype-basics) or read more about the [concepts behind Metatype](/docs/concepts/mental-model).\\n\\n:::"},{"id":"/2023/03/15/emulating-servers","metadata":{"permalink":"/blog/2023/03/15/emulating-servers","editUrl":"https://github.com/metatypedev/metatype/tree/main/docs/metatype.dev/blog/2023-03-15-emulating-servers/index.mdx","source":"@site/blog/2023-03-15-emulating-servers/index.mdx","title":"Emulating your server nodes locally","description":"Introducing the Embedded Typegate","date":"2023-03-15T00:00:00.000Z","tags":[],"readingTime":3.07,"hasTruncateMarker":false,"authors":[],"frontMatter":{},"unlisted":false,"prevItem":{"title":"Programmable glue for developers","permalink":"/blog/2023/06/18/programmable-glue"}},"content":"import BlogIntro from \\"@site/src/components/BlogIntro\\";\\nimport UpgradeMetatype from \\"../../shared/upgrade/index.mdx\\";\\n\\n\\n<BlogIntro text=\\"Metatype is a platform which allows developers to solely focus on functional aspect of their applications by powering them with rich declarative API development tools to program and deploy in a cloud first environment. One component of Metatype is the Typegate, a serverless GraphQL/REST gateway for processing queries. This post is about how we in metatype made a dev friendly access to a typegate instance namely Embedded Typegate.\\" />\\n\\n## Introducing the Embedded Typegate\\n\\nThe embedded typegate is a feature that comes with the [Meta CLI](/docs/reference/meta-cli) which provides the option of spinning a typegate instance from the CLI with minimum configurations and installations needed from the developer. All that is required to access the _Embedded Typegate_ is to install _Meta CLI_. The spawned typegate instance behaves similarly to cloud-deployed typegates.\\n\\n## The motive\\n\\nThere are more than a couple of reasons why a developer would be tempted to use an emedded typegate. While developers can start a typegate instance using docker compose, the developer needs to install docker as a dependency to run the typegate container. Even though docker is familiar among many developers, it can sometimes be tricky and unbeknownst to some developers. We at metatype highly value the developer experience and one reason for adding the _embedded typegate_ feature to the _Meta CLI_ is for users to have a smooth experience with our system by providing a docker compose free experience.\\nThis feature provides a great utility for developers to author and test typegraphs in their local machine before deploying them to production level typegate instances on the cloud.\\nAdditionally, developers need not concern themselves with deployment configurations which are needed only during deployment. The only need to focus their energy and time in developing the right application and easily test them on _embedded typegate_ running from the terminal. To add more to what is said, as the typegate engine keeps evolving, users will be abstracted away from the different configurations which might be added on the future. The _Meta CLI_ will abstract much of what\'s not needed in a dev environment. Thus, leaving less headaches to developers on new changes.\\nUltimately, The _embedded typegate_ is designed to be a good dev environment friendly tool which faciliates development time.\\n\\n## Quick First hand example\\n\\n### Install the v0.3.x series\\n\\nEither of the two [Typegraph](/docs/reference/typegraph) SDKs are needed to author typegraphs. For this example, the node SDK will be used.\\n\\nFirst, make sure the _Meta CLI_ is installed.\\n\\n```shell\\ncurl -fsSL https://raw.githubusercontent.com/metatypedev/metatype/main/installer.sh | bash\\n```\\n\\nNext, create a new node project using this command.\\n\\n```shell\\nmeta new --template node\\n```\\n\\nThe above command will create a sample typegraph which you can use to test the embedded typegate.\\n\\nNow, you need to install the typegraph SDK by running the command down below. The previous command generates a `package.json` with the SDK specified as a dependency.\\n\\n```shell\\nnpm install\\n```\\n\\nBefore deploying the typegraph to the embedded typegate, Run the following commands below.\\n\\n```shell\\nmeta dev\\n```\\n\\nNow that there is running instance of a typegate, you can deploy the example typegraph. From another terminal, run the command below.\\n\\n```shell\\nmeta deploy -f api/example.ts --allow-dirty --create-migration --target dev --gate http://localhost:7890\\n```\\n\\nThe typegate runs on port 7890 by default. If you access [http://localhost:7890/example](http://localhost:7890/example) on your browser, you can see an GraphQL interface to interact with the deployed typegraph. You can test the example typegraph using the following graphql query below.\\n\\n```graphql\\nquery {\\n  multilpy(first: 3, second: 5)\\n}\\n```\\n\\n<UpgradeMetatype />\\n\\n## Learn more about Metatype\\n\\nWanna dive deep into the basics of _Metaype_? check our interactive [tutorial](/docs/tutorials/metatype-basics) revolving around the core features of the system."}]}}')}}]);